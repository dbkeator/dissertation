\chapter{Related Work}

In this chapter, we will look at the state-of-the-art understanding of different topics presented in a variety of areas, which context relies on. These include techniques to annotate photos using image features, techniques to represent knowledge in ontologies, techniques to query data from a variety of sources.

\section{Photo Annotation}

\subsection{Need for Annotation}

Why do we need to annotate photos?

\subsection{Computer Vision}
\textbf{Face Verification}

\textbf{Face Recognition}

\textbf{Probabilistic Techniques}

So what are the techniques here?

\section{Context}

\subsection{Definitions}

\subsection{Role in Photo Annotation}

\subsection{Other uses in Computing}

\subsection{Modeling}

\subsection{Applications of Context}

\subsection{Industrial Momentum}

\subsection{Context-Based Systems}

\section{Knowledge Representation}

\subsection{Ontologies}

\subsection{Managing Large Ontologies}

\subsection{Data Integration using Ontologies}

The role of context in computing has been studied in \cite{chen2000survey}. The use of context in image retrieval is emphasized in \cite{jain2010content, datta2008image}. Barthelmess et al.\ extract semantic tags from noisy datasets containing discussions, speeches about a set of photos in question\cite{barthelmess2007toward}. Naaman et al.\ have exploited GPS attributes to extract place and person information \cite{naaman2005leveraging, naaman2005identity}. Rattenbury \cite{rattenbury2009methods} devised techniques to find tags which describe events or places by analyzing their spatiotemporal usage patterns. Ames and Frohlich \cite{ames2007we, frohlich2002requirements} independently describe a survey conducted to study motivations for people to tag their photos. They noticed two broad motivations: Organization of photos and Communication with photos. Time alone is used for organizing photos in \cite{graham2002time, hailpern2011youpivot}. Brave new world applications for photography have been described in \cite{gemmell2002mylifebits, dumais2003stuff}, where life logs were collected in the form of photos, emails, document scans and stored in SQL Server database, and photos were retrieved using SQL queries. The photo content was tagged by the user in this case. The Computer Vision community has contributed extensive work in the area of detecting scenes \cite{xiao2010sun}, humans \cite{dalal2005histograms} or geo localization \cite{hays2008im2gps}. Context information and image features are used in conjunction by \cite{o2009context, cao2008annotating, boutell2005beyond, cao2008eventscene} identify tags. The semantic web community is using linked data technologies to annotate and query photographs \cite{monaghan2006automating, nowack2006confoto}. Collaborative games also have been evaluated as a possible way to tag photos\cite{diakopoulos2007photoplay}. Systems like Picasa, iPhoto and \cite{graham2002time} organize photos based on time, GPS coordinates and sometimes faces in the photo. These attributes of the photo do not capture event semantics \cite{sawant2011automatic}. Events are a natural way of categorizing photo media. Events also allow large number of photos captured during a single event be organized hierarchically using subevents.

The core of their view comes from the earlier proposed definition from Brezillon [CITE], who considers context to be formed from three types of knowledge: Contextual knowledge (knowledge about entities, their environments), external knowledge (knowledge which is currently not relevant), and proceduralized context, which has to do with the reasoning applied to the current situation.

150 definitions of context by Brezillon.
 \cite{mostefaoui2004context} provides a survey of some known graph modeling techniques.